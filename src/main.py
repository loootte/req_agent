# main.py
import os
import argparse
import json
from dotenv import load_dotenv, dotenv_values
from pathlib import Path
from src.requirement_tracker.crew import run_crew  # â† è¯·æ ¹æ®ä½ çš„åŒ…åä¿®æ”¹ï¼Œä¾‹å¦‚ src.requirement_crew.crew

# å¦‚æœä½ æŠŠ crew å®šä¹‰ä¸ºä¸€ä¸ªå‡½æ•°è¿”å› Crewï¼Œä¹Ÿå¯ä»¥ç”¨ä¸‹é¢æ–¹å¼
# from src.your_crew.crew import create_requirement_crew

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡ï¼ˆå¼ºçƒˆæ¨èï¼Œæ‰€æœ‰å¯†é’¥éƒ½æ”¾è¿™é‡Œï¼‰
"""
.env æ ¼å¼
# é˜¿é‡Œäº‘é€šä¹‰åƒé—®
DASHSCOPE_API_KEY=sk-your-real-key-here

# Azure OpenAI (Microsoft CopilotåŸºç¡€)
AZURE_OPENAI_API_KEY=your-azure-openai-api-key
AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4

# xAI Grok API å¯†é’¥
GROK_API_KEY=your-xai-api-key

# LLMæ¨¡å‹é…ç½®
LLM_CONFIG=[{"key": "qwen", "name": "é€šä¹‰åƒé—® (Qwen)", "model": "qwen-max", "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1", "api_key": "", "provider": "openai", "editable": false}, {"key": "azure", "name": "Azure OpenAI (Microsoft CopilotåŸºç¡€)", "model": "azure/gpt-4", "base_url": "", "api_key": "", "provider": "azure", "editable": false}, {"key": "grok", "name": "Grok (xAI)", "model": "grok-beta", "base_url": "https://api.x.ai/v1", "api_key": "", "provider": "openai", "editable": false}]

# Confluence
CONFLUENCE_URL=https://your-company.atlassian.net
CONFLUENCE_TOKEN=your-confluence-api-token
CONFLUENCE_SPACE=REQ                  # ç©ºé—´ Key
CONFLUENCE_PARENT_ID=12345678        # å¯é€‰ï¼šçˆ¶é¡µé¢ ID

# Azure DevOpsï¼ˆå¦‚æœç”¨ ADOï¼‰
ADO_ORG_URL=https://dev.azure.com/your-org
ADO_PAT=your-personal-access-token
ADO_PROJECT=YourProjectName

# Jiraï¼ˆå¦‚æœç”¨ Jira ä»£æ›¿ ADOï¼‰
# JIRA_URL=https://your-company.atlassian.net
# JIRA_TOKEN=your-jira-api-token
# JIRA_PROJECT=PROJ
"""

def load_env_vars():
    """åŠ è½½ç¯å¢ƒå˜é‡"""
    env_path = Path(__file__).parent.parent / ".env"
    if env_path.exists():
        try:
            return dotenv_values(env_path)
        except UnicodeDecodeError:
            # å¦‚æœUTF-8è§£ç å¤±è´¥ï¼Œå°è¯•å…¶ä»–ç¼–ç 
            try:
                # å°è¯•ä½¿ç”¨gbkç¼–ç ï¼ˆå¸¸è§äºä¸­æ–‡Windowsç³»ç»Ÿï¼‰
                with open(env_path, 'r', encoding='gbk') as f:
                    content = f.read()
                # å°†å†…å®¹å†™å›ä¸ºUTF-8ç¼–ç 
                with open(env_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                # é‡æ–°åŠ è½½
                return dotenv_values(env_path)
            except:
                # æœ€åå°è¯•ä½¿ç”¨latin-1ç¼–ç 
                with open(env_path, 'r', encoding='latin-1') as f:
                    content = f.read()
                # å°†å†…å®¹å†™å›ä¸ºUTF-8ç¼–ç 
                with open(env_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                # é‡æ–°åŠ è½½
                return dotenv_values(env_path)
    return {}

def load_custom_llms():
    """åŠ è½½è‡ªå®šä¹‰LLMé…ç½®"""
    env_vars = load_env_vars()
    
    # ä»LLM_CONFIGç¯å¢ƒå˜é‡åŠ è½½æ‰€æœ‰æ¨¡å‹é…ç½®
    if "LLM_CONFIG" in env_vars:
        try:
            llm_list = json.loads(env_vars["LLM_CONFIG"])
            return {llm["key"]: llm for llm in llm_list}
        except json.JSONDecodeError:
            pass
    
    # å¦‚æœæ²¡æœ‰LLM_CONFIGæˆ–è§£æå¤±è´¥ï¼Œä»æ—§æ ¼å¼åŠ è½½
    custom_llms = {}
    for key in env_vars:
        if key.startswith("LLM_CONFIG_"):
            model_key = key[len("LLM_CONFIG_"):].lower()
            try:
                custom_llms[model_key] = json.loads(env_vars[key])
            except json.JSONDecodeError:
                pass
    
    return custom_llms

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def main():
    parser = argparse.ArgumentParser(description='éœ€æ±‚æ–‡æ¡£è‡ªåŠ¨åŒ–ç³»ç»Ÿ')
    parser.add_argument('--model', default='qwen', 
                       help='é€‰æ‹©ä½¿ç”¨çš„AIæ¨¡å‹: qwen(é€šä¹‰åƒé—®)ã€azure(Azure OpenAI)ã€grok(xAI) æˆ–è‡ªå®šä¹‰æ¨¡å‹æ ‡è¯†ç¬¦')
    args = parser.parse_args()
    
    model_type = args.model
    custom_llms = load_custom_llms()
    
    # æ£€æŸ¥æ‰€é€‰æ¨¡å‹çš„å¿…è¦ç¯å¢ƒå˜é‡
    if model_type in custom_llms:
        llm_config = custom_llms[model_type]
        if model_type == "qwen":
            required_model_vars = ["DASHSCOPE_API_KEY"]
            model_name = "é€šä¹‰åƒé—®(Qwen)"
        elif model_type == "azure":
            required_model_vars = ["AZURE_OPENAI_API_KEY", "AZURE_OPENAI_ENDPOINT"]
            model_name = "Azure OpenAI (Microsoft CopilotåŸºç¡€)"
        elif model_type == "grok":
            required_model_vars = ["GROK_API_KEY"]
            model_name = "Grok (xAI)"
        else:
            # è‡ªå®šä¹‰æ¨¡å‹
            required_model_vars = []
            model_name = f"è‡ªå®šä¹‰: {llm_config['name']}"
    else:
        required_model_vars = []
        model_name = f"æœªçŸ¥æ¨¡å‹ ({model_type})"
        
    missing_model_vars = [var for var in required_model_vars if not os.getenv(var)]
    if missing_model_vars:
        print(f"âŒ ç¼ºå°‘ {model_name} æ‰€éœ€çš„ç¯å¢ƒå˜é‡ï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®ï¼š")
        for var in missing_model_vars:
            print(f"   - {var}")
        print("\nç¨‹åºé€€å‡ºã€‚")
        return

    print(f"ğŸš€ éœ€æ±‚æ–‡æ¡£è‡ªåŠ¨åŒ– Crew å·²å°±ç»ªï¼(ä½¿ç”¨ {model_name})")
    print("è¾“å…¥ä½ æƒ³è¦æ•´ç†çš„éœ€æ±‚æè¿°ï¼ˆéšæ„æ–‡å­—ï¼‰ï¼Œæˆ‘å°†è‡ªåŠ¨ç”Ÿæˆç»“æ„åŒ–æ–‡æ¡£ã€åˆ›å»ºå·¥ä½œé¡¹å¹¶å‘å¸ƒåˆ° Confluenceã€‚")
    print("è¾“å…¥ 'exit' æˆ– 'quit' é€€å‡ºç¨‹åºã€‚\n")

    while True:
        user_input = input("ğŸ“ è¯·ç²˜è´´éœ€æ±‚æè¿°ï¼š\n").strip()

        if user_input.lower() in ["exit", "quit", "q"]:
            print("ğŸ‘‹ å†è§ï¼")
            break

        if not user_input:
            print("âš ï¸  è¾“å…¥ä¸èƒ½ä¸ºç©ºï¼Œè¯·é‡æ–°è¾“å…¥ã€‚\n")
            continue

        print(f"\nğŸ¤– Crew å¼€å§‹å·¥ä½œ(ä½¿ç”¨ {model_name})ï¼Œè¯·ç¨ç­‰...\n")

        try:
            # å¯åŠ¨ Crewï¼Œä¼ å…¥è¾“å…¥æ–‡å­—å’Œæ¨¡å‹ç±»å‹
            result = run_crew(user_input, model_type)

            print("\n=== ğŸ‰ å®Œæˆï¼===\n")
            print(result)
            print("\n" + "-"*60 + "\n")

        except Exception as e:
            print(f"\nâŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºé”™ï¼š{str(e)}")
            print("è¯·æ£€æŸ¥å·¥å…·é…ç½®ï¼ˆAPI Keyã€æƒé™ã€ç½‘ç»œï¼‰æˆ–æŸ¥çœ‹è¯¦ç»†æ—¥å¿—ã€‚\n")

if __name__ == "__main__":
    # å¯é€‰ï¼šåœ¨è¿™é‡Œå¯ä»¥åšä¸€äº›å¯åŠ¨å‰æ£€æŸ¥
    main()