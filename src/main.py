# main.py
import os
import argparse
from dotenv import load_dotenv
from src.requirement_tracker.crew import requirement_crew, run_crew  # â† è¯·æ ¹æ®ä½ çš„åŒ…åä¿®æ”¹ï¼Œä¾‹å¦‚ src.requirement_crew.crew

# å¦‚æœä½ æŠŠ crew å®šä¹‰ä¸ºä¸€ä¸ªå‡½æ•°è¿”å› Crewï¼Œä¹Ÿå¯ä»¥ç”¨ä¸‹é¢æ–¹å¼
# from src.your_crew.crew import create_requirement_crew

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡ï¼ˆå¼ºçƒˆæ¨èï¼Œæ‰€æœ‰å¯†é’¥éƒ½æ”¾è¿™é‡Œï¼‰
"""
.env æ ¼å¼
# é˜¿é‡Œäº‘é€šä¹‰åƒé—®
DASHSCOPE_API_KEY=sk-your-real-key-here

# Azure OpenAI (Microsoft CopilotåŸºç¡€)
AZURE_OPENAI_API_KEY=your-azure-openai-api-key
AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4

# xAI Grok
GROK_API_KEY=your-xai-api-key

# Confluence
CONFLUENCE_URL=https://your-company.atlassian.net
CONFLUENCE_TOKEN=your-confluence-api-token
CONFLUENCE_SPACE=REQ                  # ç©ºé—´ Key
CONFLUENCE_PARENT_ID=12345678        # å¯é€‰ï¼šçˆ¶é¡µé¢ ID

# Azure DevOpsï¼ˆå¦‚æœç”¨ ADOï¼‰
ADO_ORG_URL=https://dev.azure.com/your-org
ADO_PAT=your-personal-access-token
ADO_PROJECT=YourProjectName

# Jiraï¼ˆå¦‚æœç”¨ Jira ä»£æ›¿ ADOï¼‰
# JIRA_URL=https://your-company.atlassian.net
# JIRA_TOKEN=your-jira-api-token
# JIRA_PROJECT=PROJ
"""
load_dotenv()

def main():
    parser = argparse.ArgumentParser(description='éœ€æ±‚æ–‡æ¡£è‡ªåŠ¨åŒ–ç³»ç»Ÿ')
    parser.add_argument('--model', choices=['qwen', 'azure', 'grok'], default='qwen', 
                       help='é€‰æ‹©ä½¿ç”¨çš„AIæ¨¡å‹: qwen(é€šä¹‰åƒé—®)ã€azure(Azure OpenAI) æˆ– grok(xAI)')
    args = parser.parse_args()
    
    model_type = args.model
    
    # æ£€æŸ¥æ‰€é€‰æ¨¡å‹çš„å¿…è¦ç¯å¢ƒå˜é‡
    if model_type == "qwen":
        required_model_vars = ["DASHSCOPE_API_KEY"]
        model_name = "é€šä¹‰åƒé—®(Qwen)"
    elif model_type == "azure":
        required_model_vars = ["AZURE_OPENAI_API_KEY", "AZURE_OPENAI_ENDPOINT"]
        model_name = "Azure OpenAI (Microsoft CopilotåŸºç¡€)"
    elif model_type == "grok":
        required_model_vars = ["GROK_API_KEY"]
        model_name = "Grok (xAI)"
    else:
        required_model_vars = []
        model_name = "æœªçŸ¥æ¨¡å‹"
        
    missing_model_vars = [var for var in required_model_vars if not os.getenv(var)]
    if missing_model_vars:
        print(f"âŒ ç¼ºå°‘ {model_name} æ‰€éœ€çš„ç¯å¢ƒå˜é‡ï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®ï¼š")
        for var in missing_model_vars:
            print(f"   - {var}")
        print("\nç¨‹åºé€€å‡ºã€‚")
        return

    print(f"ğŸš€ éœ€æ±‚æ–‡æ¡£è‡ªåŠ¨åŒ– Crew å·²å°±ç»ªï¼(ä½¿ç”¨ {model_name})")
    print("è¾“å…¥ä½ æƒ³è¦æ•´ç†çš„éœ€æ±‚æè¿°ï¼ˆéšæ„æ–‡å­—ï¼‰ï¼Œæˆ‘å°†è‡ªåŠ¨ç”Ÿæˆç»“æ„åŒ–æ–‡æ¡£ã€åˆ›å»ºå·¥ä½œé¡¹å¹¶å‘å¸ƒåˆ° Confluenceã€‚")
    print("è¾“å…¥ 'exit' æˆ– 'quit' é€€å‡ºç¨‹åºã€‚\n")

    while True:
        user_input = input("ğŸ“ è¯·ç²˜è´´éœ€æ±‚æè¿°ï¼š\n").strip()

        if user_input.lower() in ["exit", "quit", "q"]:
            print("ğŸ‘‹ å†è§ï¼")
            break

        if not user_input:
            print("âš ï¸  è¾“å…¥ä¸èƒ½ä¸ºç©ºï¼Œè¯·é‡æ–°è¾“å…¥ã€‚\n")
            continue

        print(f"\nğŸ¤– Crew å¼€å§‹å·¥ä½œ(ä½¿ç”¨ {model_name})ï¼Œè¯·ç¨ç­‰...\n")

        try:
            # å¯åŠ¨ Crewï¼Œä¼ å…¥è¾“å…¥æ–‡å­—å’Œæ¨¡å‹ç±»å‹
            result = run_crew(user_input, model_type)

            print("\n=== ğŸ‰ å®Œæˆï¼===\n")
            print(result)
            print("\n" + "-"*60 + "\n")

        except Exception as e:
            print(f"\nâŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºé”™ï¼š{str(e)}")
            print("è¯·æ£€æŸ¥å·¥å…·é…ç½®ï¼ˆAPI Keyã€æƒé™ã€ç½‘ç»œï¼‰æˆ–æŸ¥çœ‹è¯¦ç»†æ—¥å¿—ã€‚\n")

if __name__ == "__main__":
    # å¯é€‰ï¼šåœ¨è¿™é‡Œå¯ä»¥åšä¸€äº›å¯åŠ¨å‰æ£€æŸ¥
    main()