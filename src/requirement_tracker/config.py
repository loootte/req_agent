import streamlit as st
from dotenv import dotenv_values
import os
from pathlib import Path
import json

def load_env_vars():
    """åŠ è½½ç¯å¢ƒå˜é‡"""
    env_path = Path(__file__).parent.parent.parent / ".env"
    if env_path.exists():
        try:
            return dotenv_values(env_path)
        except UnicodeDecodeError:
            # å¦‚æœUTF-8è§£ç å¤±è´¥ï¼Œå°è¯•å…¶ä»–ç¼–ç 
            try:
                # å°è¯•ä½¿ç”¨gbkç¼–ç ï¼ˆå¸¸è§äºä¸­æ–‡Windowsç³»ç»Ÿï¼‰
                with open(env_path, 'r', encoding='gbk') as f:
                    content = f.read()
                # å°†å†…å®¹å†™å›ä¸ºUTF-8ç¼–ç 
                with open(env_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                # é‡æ–°åŠ è½½
                return dotenv_values(env_path)
            except:
                # æœ€åå°è¯•ä½¿ç”¨latin-1ç¼–ç 
                with open(env_path, 'r', encoding='latin-1') as f:
                    content = f.read()
                # å°†å†…å®¹å†™å›ä¸ºUTF-8ç¼–ç 
                with open(env_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                # é‡æ–°åŠ è½½
                return dotenv_values(env_path)
    return {}

def save_env_vars(configs):
    """ä¿å­˜ç¯å¢ƒå˜é‡åˆ°.envæ–‡ä»¶"""
    env_path = Path(__file__).parent.parent.parent / ".env"
    
    # è¯»å–ç°æœ‰çš„ç¯å¢ƒå˜é‡
    existing_vars = {}
    if env_path.exists():
        try:
            existing_vars = dotenv_values(env_path)
        except UnicodeDecodeError:
            # å¤„ç†ç¼–ç é—®é¢˜
            try:
                with open(env_path, 'r', encoding='gbk') as f:
                    lines = f.readlines()
                # é‡å»ºç¯å¢ƒå˜é‡å­—å…¸
                for line in lines:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        existing_vars[key] = value
            except:
                try:
                    with open(env_path, 'r', encoding='latin-1') as f:
                        lines = f.readlines()
                    # é‡å»ºç¯å¢ƒå˜é‡å­—å…¸
                    for line in lines:
                        line = line.strip()
                        if line and not line.startswith('#') and '=' in line:
                            key, value = line.split('=', 1)
                            existing_vars[key] = value
                except:
                    pass
    
    # æ›´æ–°é…ç½®
    existing_vars.update(configs)
    
    # å†™å…¥æ–‡ä»¶ï¼ˆå§‹ç»ˆä½¿ç”¨UTF-8ç¼–ç ï¼‰
    with open(env_path, 'w', encoding='utf-8') as f:
        for key, value in existing_vars.items():
            if value is not None:
                # ç‰¹æ®Šå¤„ç†LLM_CONFIGï¼Œç¡®ä¿å®ƒåœ¨ä¸€è¡Œå†…å¹¶ä¸”æ­£ç¡®è½¬ä¹‰
                if key == "LLM_CONFIG":
                    escaped_value = json.dumps(json.loads(value), ensure_ascii=False)
                    f.write(f'{key}={escaped_value}\n')
                # å¤„ç†åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„å€¼
                elif ' ' in str(value) or '\n' in str(value) or '#' in str(value) or '=' in str(value):
                    # è½¬ä¹‰å¼•å·
                    escaped_value = str(value).replace('"', '\\"')
                    f.write(f'{key}="{escaped_value}"\n')
                else:
                    f.write(f'{key}={value}\n')
            else:
                f.write(f'{key}=\n')

def load_custom_llms():
    """åŠ è½½è‡ªå®šä¹‰LLMé…ç½®"""
    env_vars = load_env_vars()
    
    # ä»LLM_CONFIGç¯å¢ƒå˜é‡åŠ è½½æ‰€æœ‰æ¨¡å‹é…ç½®
    if "LLM_CONFIG" in env_vars:
        try:
            llm_list = json.loads(env_vars["LLM_CONFIG"])
            return {llm["key"]: llm for llm in llm_list}
        except json.JSONDecodeError as e:
            print(f"JSONè§£æé”™è¯¯: {e}")
            print(f"LLM_CONFIGå†…å®¹: {env_vars['LLM_CONFIG']}")
            pass
    
    # å¦‚æœæ²¡æœ‰LLM_CONFIGæˆ–è§£æå¤±è´¥ï¼Œä»æ—§æ ¼å¼åŠ è½½
    custom_llms = {}
    for key in env_vars:
        if key.startswith("LLM_CONFIG_"):
            model_key = key[len("LLM_CONFIG_"):].lower()
            try:
                custom_llms[model_key] = json.loads(env_vars[key])
            except json.JSONDecodeError:
                pass
    
    # å¦‚æœä»ç„¶æ²¡æœ‰æ¨¡å‹é…ç½®ï¼Œåˆ™åˆå§‹åŒ–é»˜è®¤é…ç½®
    if not custom_llms:
        custom_llms = get_default_llms()
        
    return custom_llms

def save_custom_llms(custom_llms):
    """ä¿å­˜è‡ªå®šä¹‰LLMé…ç½®"""
    # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
    llm_list = []
    for key, config in custom_llms.items():
        config["key"] = key
        llm_list.append(config)
    
    # ä¿å­˜ä¸ºå•ä¸ªJSONç¯å¢ƒå˜é‡
    save_env_vars({"LLM_CONFIG": json.dumps(llm_list, ensure_ascii=False)})

def get_default_llms():
    """è·å–é»˜è®¤LLMé…ç½®"""
    return {
        "qwen": {
            "key": "qwen",
            "name": "é€šä¹‰åƒé—® (Qwen)",
            "model": "qwen-max",
            "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
            "api_key": "",
            "provider": "openai",
            "editable": False
        },
        "azure": {
            "key": "azure",
            "name": "Azure OpenAI (Microsoft CopilotåŸºç¡€)",
            "model": "azure/gpt-4",
            "base_url": "",
            "api_key": "",
            "provider": "azure",
            "editable": False
        },
        "grok": {
            "key": "grok",
            "name": "Grok (xAI)",
            "model": "grok-beta",
            "base_url": "https://api.x.ai/v1",
            "api_key": "",
            "provider": "openai",
            "editable": False
        }
    }

def initialize_default_llms_in_env():
    """åˆå§‹åŒ–é»˜è®¤LLMåˆ°ç¯å¢ƒå˜é‡ä¸­ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰"""
    # åªæœ‰åœ¨LLM_CONFIGå˜é‡ä¸å­˜åœ¨æ—¶æ‰åˆå§‹åŒ–
    custom_llms = load_custom_llms()
    
    # å¦‚æœæ²¡æœ‰æ¨¡å‹é…ç½®ï¼Œåˆ™åˆå§‹åŒ–é»˜è®¤é…ç½®
    if not custom_llms:
        default_llms = get_default_llms()
        save_custom_llms(default_llms)
        return default_llms
    
    return custom_llms

def show_config_page():
    st.set_page_config(
        page_title="LLM é…ç½®",
        page_icon="âš™ï¸",
        layout="wide"
    )

    st.title("âš™ï¸ LLM æ¨¡å‹é…ç½®")

    # åŠ è½½å½“å‰é…ç½®
    current_configs = load_env_vars()
    custom_llms = load_custom_llms()
    
    # å¦‚æœæ²¡æœ‰æ¨¡å‹é…ç½®ï¼Œåˆå§‹åŒ–é»˜è®¤é…ç½®
    if not custom_llms:
        custom_llms = initialize_default_llms_in_env()
    
    # æ¨¡å‹é€‰æ‹©
    st.header("ğŸ¤– é»˜è®¤æ¨¡å‹é€‰æ‹©")
    
    current_model = current_configs.get("SELECTED_MODEL", "qwen")
    selected_model = st.selectbox(
        "é€‰æ‹©é»˜è®¤æ¨¡å‹:",
        options=list(custom_llms.keys()),
        format_func=lambda x: custom_llms[x]["name"],
        index=list(custom_llms.keys()).index(current_model) if current_model in custom_llms else 0
    )
    
    st.markdown("---")
    
    # æ‰€æœ‰æ¨¡å‹é…ç½®åŒºåŸŸ
    st.header("ğŸ”§ æ¨¡å‹é…ç½®")
    
    # åˆ›å»ºä¸€ä¸ªå‰¯æœ¬ç”¨äºä¸´æ—¶ä¿®æ”¹
    temp_custom_llms = custom_llms.copy()
    
    for key, llm_config in custom_llms.items():
        with st.expander(f"{'ğŸ”§' if llm_config.get('editable', True) else 'ğŸ”’'} {llm_config['name']} ({key})", 
                         expanded=(selected_model == key)):
            
            col1, col2 = st.columns([4, 1])
            with col1:
                # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯ï¼ˆä½¿ç”¨ä¸´æ—¶å˜é‡å­˜å‚¨æ›´æ”¹ï¼‰
                name = st.text_input("æ˜¾ç¤ºåç§°:", value=llm_config["name"], key=f"name_{key}", 
                                   disabled=not llm_config.get("editable", True))
                model = st.text_input("æ¨¡å‹æ ‡è¯†:", value=llm_config["model"], key=f"model_{key}", 
                                    disabled=not llm_config.get("editable", True))
                base_url = st.text_input("APIç«¯ç‚¹:", value=llm_config["base_url"], key=f"url_{key}", 
                                       disabled=not llm_config.get("editable", True))
                
                # APIå¯†é’¥å¤„ç†
                if key == "qwen":
                    api_key_value = current_configs.get("DASHSCOPE_API_KEY", llm_config.get("api_key", ""))
                elif key == "azure":
                    api_key_value = current_configs.get("AZURE_OPENAI_API_KEY", llm_config.get("api_key", ""))
                elif key == "grok":
                    api_key_value = current_configs.get("GROK_API_KEY", llm_config.get("api_key", ""))
                else:
                    api_key_value = llm_config.get("api_key", "")
                    
                api_key = st.text_input("APIå¯†é’¥:", value=api_key_value, type="password", key=f"key_{key}", 
                                      disabled=not llm_config.get("editable", True))
                provider = st.selectbox("æä¾›å•†:", ["openai", "azure"], 
                                      index=0 if llm_config["provider"] == "openai" else 1, 
                                      key=f"provider_{key}", 
                                      disabled=not llm_config.get("editable", True))
            
            with col2:
                # åªæœ‰è‡ªå®šä¹‰æ¨¡å‹å¯ä»¥åˆ é™¤
                if llm_config.get("editable", True):
                    if st.button("ğŸ—‘ï¸ åˆ é™¤", key=f"delete_{key}"):
                        if key in temp_custom_llms:
                            del temp_custom_llms[key]
                            # ç«‹å³ä¿å­˜æ›´æ”¹
                            save_custom_llms(temp_custom_llms)
                            st.success("âœ… æ¨¡å‹å·²åˆ é™¤ï¼")
                            st.rerun()
                else:
                    st.caption("ç³»ç»Ÿé»˜è®¤æ¨¡å‹")
                    
            # æ›´æ–°ä¸´æ—¶é…ç½®ï¼ˆå¦‚æœå¯ç¼–è¾‘ï¼‰
            if llm_config.get("editable", True):
                temp_custom_llms[key] = {
                    "key": key,
                    "name": name,
                    "model": model,
                    "base_url": base_url,
                    "api_key": api_key,
                    "provider": provider,
                    "editable": True
                }
            # æ›´æ–°é»˜è®¤æ¨¡å‹çš„APIå¯†é’¥ï¼ˆå³ä½¿ä¸å¯ç¼–è¾‘ä¹Ÿè¦æ›´æ–°å†…å­˜ä¸­çš„å€¼ï¼‰
            else:
                temp_custom_llms[key] = llm_config.copy()
                temp_custom_llms[key]["api_key"] = api_key_value
    
    st.markdown("---")
    
    # æ·»åŠ æ–°è‡ªå®šä¹‰LLM
    st.header("â• æ·»åŠ è‡ªå®šä¹‰LLM")
    with st.form("new_custom_llm"):
        new_key = st.text_input("å”¯ä¸€æ ‡è¯†ç¬¦ (ä¾‹å¦‚: my-custom-model)")
        new_name = st.text_input("æ˜¾ç¤ºåç§° (ä¾‹å¦‚: æˆ‘çš„è‡ªå®šä¹‰æ¨¡å‹)")
        new_model = st.text_input("æ¨¡å‹æ ‡è¯† (ä¾‹å¦‚: gpt-4)")
        new_base_url = st.text_input("APIç«¯ç‚¹")
        new_api_key = st.text_input("APIå¯†é’¥", type="password")
        new_provider = st.selectbox("æä¾›å•†", ["openai", "azure"])
        
        if st.form_submit_button("â• æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹"):
            if new_key and new_name and new_model and new_base_url and new_api_key:
                # æ£€æŸ¥æ ‡è¯†ç¬¦æ˜¯å¦å·²å­˜åœ¨
                if new_key in temp_custom_llms:
                    st.error("âŒ æ ‡è¯†ç¬¦å·²å­˜åœ¨ï¼Œè¯·ä½¿ç”¨ä¸åŒçš„æ ‡è¯†ç¬¦")
                else:
                    temp_custom_llms[new_key] = {
                        "key": new_key,
                        "name": new_name,
                        "model": new_model,
                        "base_url": new_base_url,
                        "api_key": new_api_key,
                        "provider": new_provider,
                        "editable": True
                    }
                    # ç«‹å³ä¿å­˜æ›´æ”¹
                    save_custom_llms(temp_custom_llms)
                    st.success("âœ… è‡ªå®šä¹‰æ¨¡å‹å·²æ·»åŠ ï¼")
                    st.rerun()
            else:
                st.error("âŒ è¯·å¡«å†™æ‰€æœ‰å­—æ®µ")
    
    st.markdown("---")
    
    # ä¿å­˜é…ç½®æŒ‰é’®
    if st.button("ğŸ’¾ ä¿å­˜é…ç½®", type="primary"):
        configs_to_save = {
            "SELECTED_MODEL": selected_model,
        }
        
        # ä¿å­˜é»˜è®¤æ¨¡å‹çš„APIå¯†é’¥åˆ°å„è‡ªçš„æ ‡å‡†ç¯å¢ƒå˜é‡
        for key, llm_config in temp_custom_llms.items():
            if key == "qwen":
                qwen_key = st.session_state.get(f"key_{key}", "")
                if qwen_key:
                    configs_to_save["DASHSCOPE_API_KEY"] = qwen_key
                    
            elif key == "azure":
                azure_key = st.session_state.get(f"key_{key}", "")
                azure_url = st.session_state.get(f"url_{key}", "")
                if azure_key:
                    configs_to_save["AZURE_OPENAI_API_KEY"] = azure_key
                if azure_url:
                    configs_to_save["AZURE_OPENAI_ENDPOINT"] = azure_url
                # éƒ¨ç½²åéœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œè¿™é‡Œå‡è®¾é»˜è®¤ä¸ºgpt-4
                configs_to_save["AZURE_OPENAI_DEPLOYMENT_NAME"] = "gpt-4"
                    
            elif key == "grok":
                grok_key = st.session_state.get(f"key_{key}", "")
                if grok_key:
                    configs_to_save["GROK_API_KEY"] = grok_key
        
        # ä¿å­˜è‡ªå®šä¹‰LLMé…ç½®åˆ°LLM_CONFIGç¯å¢ƒå˜é‡ï¼ˆåŒ…å«APIå¯†é’¥ï¼‰
        llm_list = []
        for key, config in temp_custom_llms.items():
            # ç¡®ä¿APIå¯†é’¥ä¹Ÿè¢«ä¿å­˜åˆ°LLM_CONFIGä¸­
            if key == "qwen":
                config["api_key"] = st.session_state.get(f"key_{key}", "")
            elif key == "azure":
                config["api_key"] = st.session_state.get(f"key_{key}", "")
            elif key == "grok":
                config["api_key"] = st.session_state.get(f"key_{key}", "")
            
            config["key"] = key
            llm_list.append(config)
        configs_to_save["LLM_CONFIG"] = json.dumps(llm_list, ensure_ascii=False)
        
        try:
            save_env_vars(configs_to_save)
            st.success("âœ… é…ç½®å·²ä¿å­˜æˆåŠŸï¼")
        except Exception as e:
            st.error(f"âŒ ä¿å­˜é…ç½®æ—¶å‡ºé”™: {str(e)}")
    
    # æ˜¾ç¤ºå½“å‰é…ç½®çŠ¶æ€
    st.markdown("---")
    st.header("ğŸ“Š å½“å‰é…ç½®çŠ¶æ€")
    
    configs = load_env_vars()
    current_model_name = temp_custom_llms.get(current_model, {}).get("name", "æœªçŸ¥æ¨¡å‹") if current_model in temp_custom_llms else "æœªçŸ¥æ¨¡å‹"
    st.info(f"å½“å‰é€‰æ‹©çš„æ¨¡å‹: **{current_model_name}**")
    
    # æ£€æŸ¥å„æ¨¡å‹é…ç½®çŠ¶æ€
    default_llms = get_default_llms()
    default_count = len([k for k in temp_custom_llms.keys() if k in default_llms])
    custom_count = len([k for k in temp_custom_llms.keys() if k not in default_llms])
    
    col1, col2 = st.columns(2)
    with col1:
        st.metric("é»˜è®¤æ¨¡å‹", f"âœ… {default_count} ä¸ª")
    with col2:
        st.metric("è‡ªå®šä¹‰æ¨¡å‹", f"âœ… {custom_count} ä¸ª" if custom_count > 0 else "âŒ 0 ä¸ª")

if __name__ == "__main__":
    show_config_page()